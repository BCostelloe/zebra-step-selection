{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d999bc25-8fbd-425e-bb54-6c5b3674b75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from osgeo import gdal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51d82659-3c04-40e6-98ae-2ed27bf07b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change server_mount for your system\n",
    "server_mount = '/home/blair/server/herd_hover' \n",
    "\n",
    "# Specify radius of viewshed (in meters)\n",
    "viewshed_radius = 100\n",
    "# Specify height/width of downsampled viewshed, e.g. 512 will return an array of 512x512 pixels\n",
    "viewshed_hw = 512\n",
    "# Specify radius (meters) used to define social density (number of conspecifics within this radius = social density)\n",
    "social_radius = 10\n",
    "\n",
    "data_folder = os.path.join(server_mount, 'zebra_movement_data')\n",
    "steps_dir = os.path.join(data_folder, 'steps_5m')\n",
    "social_data_dir = os.path.join(data_folder, 'social_data')\n",
    "obs_metadata_file = os.path.join(data_folder, 'observation_metadata.csv')\n",
    "track_metadata_file = os.path.join(data_folder, 'track_metadata.csv')\n",
    "#ob_dist_dir = os.path.join(data_folder, 'observer_distances')\n",
    "rasters_dir = os.path.join(data_folder, 'rasters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d46ac3b-7ce2-4430-9f9d-97111bf32906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to generate the viewshed\n",
    "def generate_viewshed(dsm_file, X, Y, height, targetRasterName, radius):\n",
    "    src_ds = gdal.Open(dsm_file)      \n",
    "    srcBand = src_ds.GetRasterBand(1)\n",
    "    #c_options = ['COMPRESS=LZW', 'NUM_THREADS=4']\n",
    "    c_options = ['NUM_THREADS=4']\n",
    "    \n",
    "    gdal.ViewshedGenerate(\n",
    "        srcBand=srcBand,\n",
    "        driverName=\"GTIFF\",\n",
    "        targetRasterName=targetRasterName,\n",
    "        creationOptions=c_options,\n",
    "        observerX=X,\n",
    "        observerY=Y,\n",
    "        observerHeight=height,\n",
    "        targetHeight=0,\n",
    "        visibleVal=1,\n",
    "        invisibleVal=0,\n",
    "        outOfRangeVal=-10000,\n",
    "        noDataVal=-10000,\n",
    "        dfCurvCoeff=0.85714,\n",
    "        mode=1,\n",
    "        maxDistance=radius\n",
    "    )\n",
    "    src_ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3509a417-00d0-4e17-8370-825de3ec267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZebraMovementDataset(Dataset):\n",
    "    def __init__(self, steps_dir, obs_metadata_file, track_metadata_file, rasters_dir, viewshed_radius, viewshed_hw, social_data_dir, social_radius):\n",
    "        step_files = glob.glob(os.path.join(steps_dir, \"*.pkl\"))\n",
    "        self.steps = pd.concat((pd.read_pickle(f) for f in step_files), ignore_index = True)\n",
    "        self.obs_metadata = pd.read_csv(obs_metadata_file)\n",
    "        self.track_metadata = pd.read_csv(track_metadata_file)\n",
    "        self.viewshed_radius = viewshed_radius\n",
    "        self.viewshed_hw = viewshed_hw\n",
    "        self.social_data_dir = social_data_dir\n",
    "        self.social_radius = social_radius\n",
    "\n",
    "    def __n_obs__(self): ## gives the number of observations in the dataset\n",
    "        return len(self.obs_metadata)\n",
    "\n",
    "    ### The following two functions are inaccurate because the track metadata file includes\n",
    "    ### lines for tracks that are filtered out because they are too short (no steps or only 1 step)\n",
    "    # def __n_tracks__(self): ## gives the number of tracks in the dataset\n",
    "    #     return len(self.track_metadata)\n",
    "\n",
    "    # def __n_animals__(self): ## gives the number of unique animals in the dataset\n",
    "    #     return len(self.track_metadata.individual_ID.unique())\n",
    "\n",
    "    def __len__(self): ## here somehow need to get the total number of observed + inferred steps\n",
    "        return(len(self.steps))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        step_id = self.steps.loc[idx, \"id\"] # unique ID for each step\n",
    "        frame = self.steps.loc[idx, \"frame\"] # video frame (time step) corresponding to step location\n",
    "        \n",
    "        # METADATA\n",
    "        ob_num = step_id.split('_')[0].split('b')[1]\n",
    "        observation = \"observation\" + step_id.split('_')[0].split('b')[1] # observation number\n",
    "        track_num = int(step_id.split('_')[1].split('k')[1]) \n",
    "        track = observation + '-track' + \"{:02d}\".format(track_num) # track id ('ob000-track00')\n",
    "        animal_id = self.track_metadata[(self.track_metadata['observation'] == observation) & (self.track_metadata['track'] == track_num)]['individual_ID'].item() # animal id (some animals have multiple tracks)\n",
    "        species = self.track_metadata[(self.track_metadata['observation'] == observation) & (self.track_metadata['track'] == track_num)]['species'].item() # currently either pz (plains zebra) or gz (grevy's zebra)\n",
    "        age_class = self.track_metadata[(self.track_metadata['observation'] == observation) & (self.track_metadata['track'] == track_num)]['age'].item() # either \"adult\" or \"young\"\n",
    "        scare = True if frame >= self.obs_metadata[self.obs_metadata['observation'] == observation]['scare_frame'].item() else False # has a scare happened before this frame?\n",
    "        \n",
    "        # STEP INFO\n",
    "        step_type = 'observed' if step_id.split('_')[-1] == 'ob' else 'simulated' # observed (real steps) or simulated (fake steps - 5 simulated per real step)\n",
    "        if self.steps[self.steps['id'] == step_id]['prev_step'].item() == None:\n",
    "            prev_step_id = \"None\"\n",
    "        else:\n",
    "            prev_step_id = self.steps[self.steps['id'] == step_id]['prev_step'].item()# id of previous observed step\n",
    "        \n",
    "        step_length_m = self.steps[self.steps['id'] == step_id]['step_length_m'].item() # length of step (should be approximately 5m)\n",
    "        step_duration_s = self.steps[self.steps['id'] == step_id]['step_duration_s'].item() # time duration of step in seconds\n",
    "        step_speed_mps = self.steps[self.steps['id'] == step_id]['step_speed_mps'].item() # speed of step in meters per second\n",
    "        \n",
    "        # SPATIAL RELATIONSHIP TO OBSERVATION FIELD TEAM\n",
    "        ob_dist = self.steps[self.steps['id'] == step_id]['dist_to_observer'].item() # absolute distance between the step location and the stationary observation team (in meters)\n",
    "        delta_ob_dist = self.steps[self.steps['id'] == step_id]['delta_observer_dist'].item() # change in distance to the observation team since the last observed step location: negative values mean animal has moved closer\n",
    "        ob_angle = self.steps[self.steps['id'] == step_id]['angle_to_observers'].item() # angle of step relative to vector toward observation team - 0 means moving directly toward observation team, 180 means moving directly away.\n",
    "\n",
    "        # VIEWSHED CALCULATION\n",
    "        # observer heights are stored in self.steps in column observer_height\n",
    "        # dsm rasters are in rasters_dir/DSMs\n",
    "        X = self.steps.loc[idx, 'lon']\n",
    "        Y = self.steps.loc[idx, 'lat']\n",
    "        height = float(self.steps.loc[idx, 'observer_height'])\n",
    "        map_name = self.obs_metadata[self.obs_metadata['observation'] == observation]['big_map'].item() + '_dsm.tif'\n",
    "        dsm = os.path.join(rasters_dir, 'DSMs', map_name)\n",
    "        # save the raster in memory\n",
    "        full_raster_name = step_id + '_tempraster.tif'\n",
    "        full_raster = '/vsimem/' + full_raster_name\n",
    "        # generate the full-resolution viewshed\n",
    "        generate_viewshed(dsm, X, Y, height, full_raster, self.viewshed_radius)\n",
    "        # load the full-resolution viewshed and calculate the proportion of pixels that are visible\n",
    "        vs = gdal.OpenEx(full_raster)\n",
    "        vshed = vs.GetRasterBand(1)\n",
    "        mean_full = vshed.GetStatistics(0, 1)[2]\n",
    "        # downsample the raster to the specified dimensions\n",
    "        downsample_raster_name = step_id + 'tempraster2.tif'\n",
    "        downsample_raster = '/vsimem/' + downsample_raster_name\n",
    "        \n",
    "        kws = gdal.WarpOptions(\n",
    "            format = 'GTiff',\n",
    "            width = self.viewshed_hw,\n",
    "            height = self.viewshed_hw,\n",
    "            srcBands = [1],\n",
    "            resampleAlg = 'average', # each pixel in the downsampled raster is the mean of the pixels it overlaps in the full-res raster\n",
    "            outputType = gdal.GDT_Float64\n",
    "        )\n",
    "        gdal.Warp(\n",
    "            destNameOrDestDS=downsample_raster,\n",
    "            srcDSOrSrcDSTab=vs, options=kws)\n",
    "        \n",
    "        vs = None\n",
    "        gdal.Unlink(full_raster)\n",
    "        # convert downsampled raster into numpy array\n",
    "        mvs = gdal.OpenEx(downsample_raster)\n",
    "        viewshed_array = mvs.ReadAsArray(buf_type=gdal.GDT_Float64)\n",
    "        mvs = None\n",
    "        viewshed_array[viewshed_array==5]=np.nan # \"no data\" value in the original viewshed is 5, replace it here with np.nan\n",
    "        gdal.Unlink(downsample_raster)\n",
    "        \n",
    "        # scarers_dist = STILL NEED TO ADD - How far is this location from the scarers?\n",
    "        # scarers_ang = STILL NEED TO ADD - What is the angle of the step relative to the direction to the scarers?\n",
    "        # delta_scarers_dist = STILL NEED TO ADD - How has distance to the scarers changed with this step?\n",
    "\n",
    "        # HABITAT VARIABLES\n",
    "        slope = self.steps.loc[idx, 'ground_slope'] # angle of incline of step from last point to current point\n",
    "        road = self.steps.loc[idx, 'road'] # is the point on a road (1) or not (0)?\n",
    "        # trail = Boolean, is the point on a trail?\n",
    "\n",
    "        # SOCIAL VARIABLES\n",
    "        social_data_file = os.path.join(self.social_data_dir, 'ob%s_track%s_socialdata.pkl' %(ob_num, \"{:02d}\".format(track_num)))\n",
    "        with open(social_data_file, 'rb') as f:\n",
    "            social_data = pickle.load(f)\n",
    "        focal_dat = [d for d in social_data if d['step_id'] == step_id][0]\n",
    "        social = pd.DataFrame.from_dict(focal_dat)\n",
    "        nn_dist = min(social[social['neighbor_spps'] == species]['neighbor_distances']) if len(social[social['neighbor_spps'] == species]) >0 else np.nan # distance to nearest conspecific neighbor\n",
    "        nn_dist_hetero = min(social[social['neighbor_spps'] != species]['neighbor_distances']) if len(social[social['neighbor_spps'] != species]) >0 else np.nan # distance to nearest heterospecific neighbor\n",
    "        soc_dens = len(social[(social['neighbor_spps'] == species) & (social['neighbor_distances'] <= self.social_radius)]) # social density, conspecifics only\n",
    "        tot_dens = len(social[social['neighbor_distances'] <= self.social_radius]) # social density, all species\n",
    "        prop_vis = len(social[(social['neighbor_spps'] == species) & (social['neighbor_visibility'] == True)])/(len(social[(social['neighbor_spps'] == species) & (social['neighbor_visibility'] == True)]) + len(social[(social['neighbor_spps'] == species) & (social['neighbor_visibility'] == False)])) # proportion of conspecifics in social radius\n",
    "        prop_vis_tot = len(social[social['neighbor_visibility'] == True])/(len(social[social['neighbor_visibility'] == True]) + len(social[social['neighbor_visibility'] == False])) # proportion of all animals in social radius\n",
    "        # used = used space - how many conspecifics have used this space (within 2m buffer) so far in observation?\n",
    "        \n",
    "        return step_id, step_type, observation, track, animal_id, species, age_class, step_length_m, step_duration_s, step_speed_mps, ob_dist, delta_ob_dist, ob_angle, scare, mean_full, viewshed_array, slope, road, nn_dist, nn_dist_hetero, soc_dens, tot_dens, prop_vis, prop_vis_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eb938634-8d58-431d-9548-e898fa75cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ZebraMovementDataset(steps_dir, \n",
    "                               obs_metadata_file, \n",
    "                               track_metadata_file, \n",
    "                               rasters_dir, \n",
    "                               viewshed_radius = viewshed_radius, \n",
    "                               viewshed_hw = viewshed_hw, \n",
    "                               social_data_dir = social_data_dir,\n",
    "                               social_radius = social_radius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0f294b2a-9b84-4a62-9ad5-499a46e20616",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size = 2, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9256bb90-1ac3-4501-95e2-310d7d55ca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "87f133d8-aa93-484d-80ba-c504d4d16334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ob088_track13_f80503_sim-1', 'ob015_track07_f12587_sim-1'),\n",
       " ('simulated', 'simulated'),\n",
       " ('observation088', 'observation015'),\n",
       " ('observation088-track13', 'observation015-track07'),\n",
       " ('088-013', '015-007'),\n",
       " ('gz', 'gz'),\n",
       " ('young', 'adult'),\n",
       " tensor([5.0229, 5.0105], dtype=torch.float64),\n",
       " tensor([1.0667, 4.4667], dtype=torch.float64),\n",
       " tensor([4.7090, 1.1218], dtype=torch.float64),\n",
       " tensor([609.1954, 308.2825], dtype=torch.float64),\n",
       " tensor([4.3583, 0.6372], dtype=torch.float64),\n",
       " tensor([150.0730,  96.8441], dtype=torch.float64),\n",
       " tensor([ True, False]),\n",
       " tensor([0.0859, 0.0299], dtype=torch.float64),\n",
       " tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64),\n",
       " tensor([3.1299, 5.2229], dtype=torch.float64),\n",
       " tensor([0, 0], dtype=torch.int32),\n",
       " tensor([2.7018, 4.1465], dtype=torch.float64),\n",
       " tensor([nan, nan], dtype=torch.float64),\n",
       " tensor([8, 2]),\n",
       " tensor([8, 2]),\n",
       " tensor([0.7647, 1.0000], dtype=torch.float64),\n",
       " tensor([0.7647, 1.0000], dtype=torch.float64)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a5f5fd-8f86-4356-8224-2c259e64423f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6adc3892-62c4-44fd-8f9c-50fec869c50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from stepselector.data_loader import ZebraDataset, ZebraBatchSampler, custom_collate\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import os\n",
    "import joblib\n",
    "from osgeo import gdal\n",
    "from tqdm.notebook import tqdm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "gdal.UseExceptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "66db34a5-209a-4576-9acb-d920f3538e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change server_mount for your system\n",
    "server_mount = '/home/blair/server/herd_hover'\n",
    "data_folder = os.path.join(server_mount, 'zebra_movement_data')\n",
    "\n",
    "# Import pre-loaded data\n",
    "data_file = os.path.join(data_folder, 'loaded_data_10msteps.csv')\n",
    "data = pd.read_csv(data_file)\n",
    "data.drop(labels = ['Unnamed: 0'], axis = 1, inplace = True)\n",
    "data.rename(columns={'0': 'target_id',\n",
    "                     '1': 'angle_to_observer',\n",
    "                     '2': 'dist_to_observer',\n",
    "                     '3': 'delta_observer_dist',\n",
    "                     '4': 'road',\n",
    "                     '5': 'ground_slope',\n",
    "                     '6': 'visibility',\n",
    "                     '7': 'social_dens',\n",
    "                     '8': 'social_vis'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "27d17587-764f-4192-a6c8-4a1d0d932f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target_id              False\n",
       "angle_to_observer      False\n",
       "dist_to_observer       False\n",
       "delta_observer_dist    False\n",
       "road                   False\n",
       "ground_slope           False\n",
       "visibility             False\n",
       "social_dens            False\n",
       "social_vis             False\n",
       "label                  False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are missing data\n",
    "data.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "e3315db1-1833-430f-ba12-62182e5ab9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no NANs, drop the id column\n",
    "data.drop(labels = ['target_id'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "b91264be-9cc9-41a8-9ede-115aa6a27f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # impute missing values if there are any\n",
    "# imputer = SimpleImputer(strategy = 'mean')\n",
    "# df = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "# df = df_imputed.astype({'road': 'int32', 'social_dens':'int32', 'label':'int32'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "318ae6f4-f31a-480f-b2ab-8b59bda24d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-transform distances\n",
    "data['log_dist_to_observer'] = np.log1p(data['dist_to_observer'])\n",
    "\n",
    "# convert angles to sines and cosines\n",
    "data['sin_angle_to_observers'] = np.sin(np.deg2rad(data['angle_to_observer']))\n",
    "data['cos_angle_to_observers'] = np.cos(np.deg2rad(data['angle_to_observer']))\n",
    "data['sin_ground_slope'] = np.sin(np.deg2rad(data['ground_slope']))\n",
    "data['cos_ground_slope'] = np.cos(np.deg2rad(data['ground_slope']))\n",
    "\n",
    "# drop untransformed columns\n",
    "data = data.drop(columns =['dist_to_observer', 'angle_to_observer', 'ground_slope'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "10024d8b-a8e8-4264-a959-02c5ad056052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize scalers\n",
    "\n",
    "# visibility is a proportion between 0 and 1\n",
    "visibility_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "# social scaler used for counts of visible neighbors (social_vis) and neighbors within 10m (social_dens)\n",
    "social_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "# log_distance scaler used for transformed distance to observers, and delta distance to observer\n",
    "dist_scaler = StandardScaler()\n",
    "\n",
    "# sin_cos_scaler used for transformed angles (ground_slope and angle_to_observer)\n",
    "sin_cos_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "540301d6-90e9-4559-a1a6-a5ff1df7a615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply scalers\n",
    "#df['ground_slope'] = slope_scaler.fit_transform(df[['ground_slope']])\n",
    "data['visibility'] = visibility_scaler.fit_transform(data[['visibility']])\n",
    "data['social_dens'] = social_scaler.fit_transform(data[['social_dens']])\n",
    "data['social_vis'] = social_scaler.fit_transform(data[['social_vis']])\n",
    "data['log_dist_to_observer'] = dist_scaler.fit_transform(data[['log_dist_to_observer']])\n",
    "data['delta_observer_dist'] = dist_scaler.fit_transform(data[['delta_observer_dist']])\n",
    "data[['sin_angle_to_observers', 'cos_angle_to_observers', 'sin_ground_slope', 'cos_ground_slope']] = sin_cos_scaler.fit_transform(data[['sin_angle_to_observers', 'cos_angle_to_observers', 'sin_ground_slope', 'cos_ground_slope']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4aa30712-6af3-4414-bbed-2d27206126e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your fighters\n",
    "data = data[['delta_observer_dist', \n",
    "                   'road', \n",
    "                   'visibility', \n",
    "                   'social_dens', \n",
    "                   'social_vis', \n",
    "                   'log_dist_to_observer', \n",
    "                   'sin_angle_to_observers',\n",
    "                   'cos_angle_to_observers',\n",
    "                   'sin_ground_slope', \n",
    "                   'cos_ground_slope', \n",
    "                   'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e2c550fe-7c81-423d-ac4b-6660504bfbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns='label')\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "18993027-5f14-4405-8746-ee83e091aaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "2c9bc6f6-9164-4907-98a4-d6ec17e35ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =           11     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.93147D-01    |proj g|=  3.59491D-02\n",
      "\n",
      "At iterate   50    f=  6.83792D-01    |proj g|=  1.42647D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "   11     51     56      1     0     0   1.437D-05   6.838D-01\n",
      "  F =  0.68379209651208606     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-19 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-19 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-19 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-19 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-19 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-19 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-19 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-19 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-19 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-19 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-19 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-19 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, n_jobs=1,\n",
       "                   penalty=None, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" checked><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000, n_jobs=1,\n",
       "                   penalty=None, verbose=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=1000, n_jobs=1,\n",
       "                   penalty=None, verbose=True)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and train the logistic regression model with parallelization\n",
    "model = LogisticRegression(max_iter=1000, n_jobs=1, verbose=True, class_weight = 'balanced', penalty = None, C=1.0)  # n_jobs=-1 uses all available cores\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "040d460d-01f4-4b2e-8c14-79bff8cc859c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.55\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the train set\n",
    "y_pred = model.predict(X_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "81e757fd-8e8d-44d8-8518-7c758fdced8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.55      0.67     14941\n",
      "           1       0.20      0.56      0.29      3006\n",
      "\n",
      "    accuracy                           0.55     17947\n",
      "   macro avg       0.53      0.55      0.48     17947\n",
      "weighted avg       0.75      0.55      0.61     17947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "08ef9c9a-5b4f-4d7b-9186-2f35a05259df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.54\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ab2d29fb-0e1a-4969-8e7a-ed164f413fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.54      0.66      3754\n",
      "           1       0.18      0.53      0.27       733\n",
      "\n",
      "    accuracy                           0.54      4487\n",
      "   macro avg       0.52      0.54      0.47      4487\n",
      "weighted avg       0.75      0.54      0.60      4487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "48060338-d85c-4be4-b8a3-9aeba3fbb1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "853c6cff-3ffe-4f17-a7c4-2e9e4a980e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Coefficients:\n",
      "[[ 0.79749041  0.19282073  0.18180063  1.0362193  -0.06083858 -0.14593827\n",
      "   0.0513544   0.62138037  0.12486286  0.05671626]]\n",
      "Model Intercept:\n",
      "[-0.28822327]\n"
     ]
    }
   ],
   "source": [
    "# Check coefficients\n",
    "coefficients = model.coef_\n",
    "intercept = model.intercept_\n",
    "print(\"Model Coefficients:\")\n",
    "print(coefficients)\n",
    "print(\"Model Intercept:\")\n",
    "print(intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6884b4eb-55b3-4d4e-9400-c60a4d40d86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>delta_observer_dist</td>\n",
       "      <td>328.923121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>road</td>\n",
       "      <td>1.033875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>visibility</td>\n",
       "      <td>4.868399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>social_dens</td>\n",
       "      <td>3.054151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>social_vis</td>\n",
       "      <td>5.892342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>log_dist_to_observer</td>\n",
       "      <td>1.271036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sin_angle_to_observers</td>\n",
       "      <td>1.318802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cos_angle_to_observers</td>\n",
       "      <td>332.761863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sin_ground_slope</td>\n",
       "      <td>1.187211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cos_ground_slope</td>\n",
       "      <td>1.127811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>label</td>\n",
       "      <td>1.182199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature         VIF\n",
       "0      delta_observer_dist  328.923121\n",
       "1                     road    1.033875\n",
       "2               visibility    4.868399\n",
       "3              social_dens    3.054151\n",
       "4               social_vis    5.892342\n",
       "5     log_dist_to_observer    1.271036\n",
       "6   sin_angle_to_observers    1.318802\n",
       "7   cos_angle_to_observers  332.761863\n",
       "8         sin_ground_slope    1.187211\n",
       "9         cos_ground_slope    1.127811\n",
       "10                   label    1.182199"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for multicolinnearity \n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['feature'] = data.columns\n",
    "vif_data['VIF'] = [variance_inflation_factor(data.values, i) for i in range(len(data.columns))]\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "0288b78b-5cdd-492d-b4b3-db10d759b3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.45913064\n",
      "Iteration 2, loss = 0.44649613\n",
      "Iteration 3, loss = 0.44453125\n",
      "Iteration 4, loss = 0.44400475\n",
      "Iteration 5, loss = 0.44319391\n",
      "Iteration 6, loss = 0.44190303\n",
      "Iteration 7, loss = 0.44065311\n",
      "Iteration 8, loss = 0.44081228\n",
      "Iteration 9, loss = 0.44013194\n",
      "Iteration 10, loss = 0.43934028\n",
      "Iteration 11, loss = 0.43854241\n",
      "Iteration 12, loss = 0.43715181\n",
      "Iteration 13, loss = 0.43885366\n",
      "Iteration 14, loss = 0.43615078\n",
      "Iteration 15, loss = 0.43632894\n",
      "Iteration 16, loss = 0.43545209\n",
      "Iteration 17, loss = 0.43515323\n",
      "Iteration 18, loss = 0.43487466\n",
      "Iteration 19, loss = 0.43351857\n",
      "Iteration 20, loss = 0.43308326\n",
      "Iteration 21, loss = 0.43325838\n",
      "Iteration 22, loss = 0.43394706\n",
      "Iteration 23, loss = 0.43199625\n",
      "Iteration 24, loss = 0.43075645\n",
      "Iteration 25, loss = 0.43072156\n",
      "Iteration 26, loss = 0.43066808\n",
      "Iteration 27, loss = 0.42903174\n",
      "Iteration 28, loss = 0.43014976\n",
      "Iteration 29, loss = 0.42913361\n",
      "Iteration 30, loss = 0.42833818\n",
      "Iteration 31, loss = 0.42781810\n",
      "Iteration 32, loss = 0.42756167\n",
      "Iteration 33, loss = 0.42657644\n",
      "Iteration 34, loss = 0.42692819\n",
      "Iteration 35, loss = 0.42684821\n",
      "Iteration 36, loss = 0.42561854\n",
      "Iteration 37, loss = 0.42578001\n",
      "Iteration 38, loss = 0.42369208\n",
      "Iteration 39, loss = 0.42437391\n",
      "Iteration 40, loss = 0.42331138\n",
      "Iteration 41, loss = 0.42282226\n",
      "Iteration 42, loss = 0.42283537\n",
      "Iteration 43, loss = 0.42182532\n",
      "Iteration 44, loss = 0.42200293\n",
      "Iteration 45, loss = 0.42146751\n",
      "Iteration 46, loss = 0.42113992\n",
      "Iteration 47, loss = 0.41949913\n",
      "Iteration 48, loss = 0.41913318\n",
      "Iteration 49, loss = 0.41898142\n",
      "Iteration 50, loss = 0.41854875\n",
      "Iteration 51, loss = 0.41794808\n",
      "Iteration 52, loss = 0.41856025\n",
      "Iteration 53, loss = 0.41777402\n",
      "Iteration 54, loss = 0.41592268\n",
      "Iteration 55, loss = 0.41674028\n",
      "Iteration 56, loss = 0.41593682\n",
      "Iteration 57, loss = 0.41431801\n",
      "Iteration 58, loss = 0.41523385\n",
      "Iteration 59, loss = 0.41420009\n",
      "Iteration 60, loss = 0.41444996\n",
      "Iteration 61, loss = 0.41240807\n",
      "Iteration 62, loss = 0.41219091\n",
      "Iteration 63, loss = 0.41103621\n",
      "Iteration 64, loss = 0.41202815\n",
      "Iteration 65, loss = 0.40987718\n",
      "Iteration 66, loss = 0.41094753\n",
      "Iteration 67, loss = 0.40914854\n",
      "Iteration 68, loss = 0.41019750\n",
      "Iteration 69, loss = 0.40782687\n",
      "Iteration 70, loss = 0.40808748\n",
      "Iteration 71, loss = 0.40780070\n",
      "Iteration 72, loss = 0.40669058\n",
      "Iteration 73, loss = 0.40690807\n",
      "Iteration 74, loss = 0.40579525\n",
      "Iteration 75, loss = 0.40483015\n",
      "Iteration 76, loss = 0.40522045\n",
      "Iteration 77, loss = 0.40433412\n",
      "Iteration 78, loss = 0.40297724\n",
      "Iteration 79, loss = 0.40493094\n",
      "Iteration 80, loss = 0.40239761\n",
      "Iteration 81, loss = 0.40182409\n",
      "Iteration 82, loss = 0.40046729\n",
      "Iteration 83, loss = 0.40164870\n",
      "Iteration 84, loss = 0.40045914\n",
      "Iteration 85, loss = 0.39937157\n",
      "Iteration 86, loss = 0.39922691\n",
      "Iteration 87, loss = 0.39842601\n",
      "Iteration 88, loss = 0.39915219\n",
      "Iteration 89, loss = 0.39767023\n",
      "Iteration 90, loss = 0.39851040\n",
      "Iteration 91, loss = 0.39672496\n",
      "Iteration 92, loss = 0.39635390\n",
      "Iteration 93, loss = 0.39750185\n",
      "Iteration 94, loss = 0.39319552\n",
      "Iteration 95, loss = 0.39574812\n",
      "Iteration 96, loss = 0.39725119\n",
      "Iteration 97, loss = 0.39295795\n",
      "Iteration 98, loss = 0.39157603\n",
      "Iteration 99, loss = 0.39271243\n",
      "Iteration 100, loss = 0.39236110\n",
      "Iteration 101, loss = 0.39017234\n",
      "Iteration 102, loss = 0.39090655\n",
      "Iteration 103, loss = 0.39086254\n",
      "Iteration 104, loss = 0.39034027\n",
      "Iteration 105, loss = 0.38780071\n",
      "Iteration 106, loss = 0.38729973\n",
      "Iteration 107, loss = 0.38659409\n",
      "Iteration 108, loss = 0.38754412\n",
      "Iteration 109, loss = 0.38668031\n",
      "Iteration 110, loss = 0.38787173\n",
      "Iteration 111, loss = 0.38767319\n",
      "Iteration 112, loss = 0.38613929\n",
      "Iteration 113, loss = 0.38390587\n",
      "Iteration 114, loss = 0.38502215\n",
      "Iteration 115, loss = 0.38467191\n",
      "Iteration 116, loss = 0.38286540\n",
      "Iteration 117, loss = 0.38200641\n",
      "Iteration 118, loss = 0.38362650\n",
      "Iteration 119, loss = 0.38272121\n",
      "Iteration 120, loss = 0.38001801\n",
      "Iteration 121, loss = 0.37997683\n",
      "Iteration 122, loss = 0.37957350\n",
      "Iteration 123, loss = 0.37914856\n",
      "Iteration 124, loss = 0.37878993\n",
      "Iteration 125, loss = 0.37666381\n",
      "Iteration 126, loss = 0.37644701\n",
      "Iteration 127, loss = 0.37875476\n",
      "Iteration 128, loss = 0.37640069\n",
      "Iteration 129, loss = 0.37764422\n",
      "Iteration 130, loss = 0.37482717\n",
      "Iteration 131, loss = 0.37681899\n",
      "Iteration 132, loss = 0.37397189\n",
      "Iteration 133, loss = 0.37322862\n",
      "Iteration 134, loss = 0.37315767\n",
      "Iteration 135, loss = 0.37316672\n",
      "Iteration 136, loss = 0.37131800\n",
      "Iteration 137, loss = 0.37058285\n",
      "Iteration 138, loss = 0.37021712\n",
      "Iteration 139, loss = 0.36788217\n",
      "Iteration 140, loss = 0.36862264\n",
      "Iteration 141, loss = 0.37399820\n",
      "Iteration 142, loss = 0.36978777\n",
      "Iteration 143, loss = 0.36761915\n",
      "Iteration 144, loss = 0.36902163\n",
      "Iteration 145, loss = 0.36872204\n",
      "Iteration 146, loss = 0.36629611\n",
      "Iteration 147, loss = 0.36590233\n",
      "Iteration 148, loss = 0.36503850\n",
      "Iteration 149, loss = 0.36518871\n",
      "Iteration 150, loss = 0.36547712\n",
      "Iteration 151, loss = 0.36456063\n",
      "Iteration 152, loss = 0.36150752\n",
      "Iteration 153, loss = 0.36197709\n",
      "Iteration 154, loss = 0.36235484\n",
      "Iteration 155, loss = 0.36071175\n",
      "Iteration 156, loss = 0.36056836\n",
      "Iteration 157, loss = 0.35987969\n",
      "Iteration 158, loss = 0.35970552\n",
      "Iteration 159, loss = 0.35998114\n",
      "Iteration 160, loss = 0.35889408\n",
      "Iteration 161, loss = 0.35844280\n",
      "Iteration 162, loss = 0.36027320\n",
      "Iteration 163, loss = 0.36076957\n",
      "Iteration 164, loss = 0.35768355\n",
      "Iteration 165, loss = 0.35899057\n",
      "Iteration 166, loss = 0.35574547\n",
      "Iteration 167, loss = 0.35524407\n",
      "Iteration 168, loss = 0.35455452\n",
      "Iteration 169, loss = 0.35598546\n",
      "Iteration 170, loss = 0.35273878\n",
      "Iteration 171, loss = 0.35740366\n",
      "Iteration 172, loss = 0.35267213\n",
      "Iteration 173, loss = 0.35551502\n",
      "Iteration 174, loss = 0.35213991\n",
      "Iteration 175, loss = 0.35180919\n",
      "Iteration 176, loss = 0.34985464\n",
      "Iteration 177, loss = 0.35071463\n",
      "Iteration 178, loss = 0.35111924\n",
      "Iteration 179, loss = 0.34791872\n",
      "Iteration 180, loss = 0.34868348\n",
      "Iteration 181, loss = 0.34854390\n",
      "Iteration 182, loss = 0.34538859\n",
      "Iteration 183, loss = 0.34665227\n",
      "Iteration 184, loss = 0.34798158\n",
      "Iteration 185, loss = 0.34830793\n",
      "Iteration 186, loss = 0.34960147\n",
      "Iteration 187, loss = 0.34839206\n",
      "Iteration 188, loss = 0.34542080\n",
      "Iteration 189, loss = 0.34711510\n",
      "Iteration 190, loss = 0.34406178\n",
      "Iteration 191, loss = 0.34228074\n",
      "Iteration 192, loss = 0.34239386\n",
      "Iteration 193, loss = 0.34405823\n",
      "Iteration 194, loss = 0.34243694\n",
      "Iteration 195, loss = 0.34139786\n",
      "Iteration 196, loss = 0.33937411\n",
      "Iteration 197, loss = 0.34209861\n",
      "Iteration 198, loss = 0.33915463\n",
      "Iteration 199, loss = 0.33999301\n",
      "Iteration 200, loss = 0.34011641\n",
      "Iteration 201, loss = 0.33815765\n",
      "Iteration 202, loss = 0.33766771\n",
      "Iteration 203, loss = 0.33684040\n",
      "Iteration 204, loss = 0.34113741\n",
      "Iteration 205, loss = 0.33823162\n",
      "Iteration 206, loss = 0.33750073\n",
      "Iteration 207, loss = 0.33642729\n",
      "Iteration 208, loss = 0.33310172\n",
      "Iteration 209, loss = 0.33421150\n",
      "Iteration 210, loss = 0.33394047\n",
      "Iteration 211, loss = 0.33571080\n",
      "Iteration 212, loss = 0.33564538\n",
      "Iteration 213, loss = 0.33595333\n",
      "Iteration 214, loss = 0.33040901\n",
      "Iteration 215, loss = 0.33095277\n",
      "Iteration 216, loss = 0.32921046\n",
      "Iteration 217, loss = 0.33125760\n",
      "Iteration 218, loss = 0.33537557\n",
      "Iteration 219, loss = 0.33134879\n",
      "Iteration 220, loss = 0.33339399\n",
      "Iteration 221, loss = 0.32690633\n",
      "Iteration 222, loss = 0.32768353\n",
      "Iteration 223, loss = 0.32892147\n",
      "Iteration 224, loss = 0.32934325\n",
      "Iteration 225, loss = 0.33134344\n",
      "Iteration 226, loss = 0.32744045\n",
      "Iteration 227, loss = 0.32840129\n",
      "Iteration 228, loss = 0.32619437\n",
      "Iteration 229, loss = 0.32422180\n",
      "Iteration 230, loss = 0.32402968\n",
      "Iteration 231, loss = 0.32534535\n",
      "Iteration 232, loss = 0.32456319\n",
      "Iteration 233, loss = 0.32538225\n",
      "Iteration 234, loss = 0.32229654\n",
      "Iteration 235, loss = 0.32505310\n",
      "Iteration 236, loss = 0.32425583\n",
      "Iteration 237, loss = 0.32276271\n",
      "Iteration 238, loss = 0.32871670\n",
      "Iteration 239, loss = 0.32346363\n",
      "Iteration 240, loss = 0.31956529\n",
      "Iteration 241, loss = 0.31968646\n",
      "Iteration 242, loss = 0.31837446\n",
      "Iteration 243, loss = 0.31995796\n",
      "Iteration 244, loss = 0.31839432\n",
      "Iteration 245, loss = 0.31930564\n",
      "Iteration 246, loss = 0.31750890\n",
      "Iteration 247, loss = 0.31787523\n",
      "Iteration 248, loss = 0.31742352\n",
      "Iteration 249, loss = 0.31830393\n",
      "Iteration 250, loss = 0.31339676\n",
      "Iteration 251, loss = 0.31787094\n",
      "Iteration 252, loss = 0.31454029\n",
      "Iteration 253, loss = 0.31605858\n",
      "Iteration 254, loss = 0.31370363\n",
      "Iteration 255, loss = 0.31157745\n",
      "Iteration 256, loss = 0.31444447\n",
      "Iteration 257, loss = 0.31165425\n",
      "Iteration 258, loss = 0.31360389\n",
      "Iteration 259, loss = 0.31040853\n",
      "Iteration 260, loss = 0.31295217\n",
      "Iteration 261, loss = 0.31192795\n",
      "Iteration 262, loss = 0.30929522\n",
      "Iteration 263, loss = 0.31038771\n",
      "Iteration 264, loss = 0.31041155\n",
      "Iteration 265, loss = 0.30998508\n",
      "Iteration 266, loss = 0.31389446\n",
      "Iteration 267, loss = 0.30698159\n",
      "Iteration 268, loss = 0.30598855\n",
      "Iteration 269, loss = 0.30805493\n",
      "Iteration 270, loss = 0.30769616\n",
      "Iteration 271, loss = 0.30943065\n",
      "Iteration 272, loss = 0.30637131\n",
      "Iteration 273, loss = 0.30477613\n",
      "Iteration 274, loss = 0.30954087\n",
      "Iteration 275, loss = 0.30387101\n",
      "Iteration 276, loss = 0.30464623\n",
      "Iteration 277, loss = 0.30364400\n",
      "Iteration 278, loss = 0.30670850\n",
      "Iteration 279, loss = 0.30333585\n",
      "Iteration 280, loss = 0.30335309\n",
      "Iteration 281, loss = 0.30072953\n",
      "Iteration 282, loss = 0.30579200\n",
      "Iteration 283, loss = 0.30440239\n",
      "Iteration 284, loss = 0.29950447\n",
      "Iteration 285, loss = 0.29864980\n",
      "Iteration 286, loss = 0.30384894\n",
      "Iteration 287, loss = 0.29871322\n",
      "Iteration 288, loss = 0.29975223\n",
      "Iteration 289, loss = 0.29961209\n",
      "Iteration 290, loss = 0.29930220\n",
      "Iteration 291, loss = 0.29670073\n",
      "Iteration 292, loss = 0.29775208\n",
      "Iteration 293, loss = 0.29522500\n",
      "Iteration 294, loss = 0.29825076\n",
      "Iteration 295, loss = 0.29567488\n",
      "Iteration 296, loss = 0.29762575\n",
      "Iteration 297, loss = 0.29650315\n",
      "Iteration 298, loss = 0.29409786\n",
      "Iteration 299, loss = 0.29274218\n",
      "Iteration 300, loss = 0.29265460\n",
      "Iteration 301, loss = 0.29416508\n",
      "Iteration 302, loss = 0.29215191\n",
      "Iteration 303, loss = 0.29344907\n",
      "Iteration 304, loss = 0.29392216\n",
      "Iteration 305, loss = 0.29301007\n",
      "Iteration 306, loss = 0.29387638\n",
      "Iteration 307, loss = 0.29135474\n",
      "Iteration 308, loss = 0.29375958\n",
      "Iteration 309, loss = 0.29621853\n",
      "Iteration 310, loss = 0.29561489\n",
      "Iteration 311, loss = 0.29158825\n",
      "Iteration 312, loss = 0.29088793\n",
      "Iteration 313, loss = 0.28715524\n",
      "Iteration 314, loss = 0.28732605\n",
      "Iteration 315, loss = 0.28969532\n",
      "Iteration 316, loss = 0.28793251\n",
      "Iteration 317, loss = 0.28858660\n",
      "Iteration 318, loss = 0.29219339\n",
      "Iteration 319, loss = 0.28705854\n",
      "Iteration 320, loss = 0.29010315\n",
      "Iteration 321, loss = 0.28651107\n",
      "Iteration 322, loss = 0.28720359\n",
      "Iteration 323, loss = 0.28741284\n",
      "Iteration 324, loss = 0.28775449\n",
      "Iteration 325, loss = 0.28575569\n",
      "Iteration 326, loss = 0.28629673\n",
      "Iteration 327, loss = 0.28576948\n",
      "Iteration 328, loss = 0.28797788\n",
      "Iteration 329, loss = 0.28358813\n",
      "Iteration 330, loss = 0.28237067\n",
      "Iteration 331, loss = 0.28066352\n",
      "Iteration 332, loss = 0.28215940\n",
      "Iteration 333, loss = 0.27909948\n",
      "Iteration 334, loss = 0.28494221\n",
      "Iteration 335, loss = 0.28241108\n",
      "Iteration 336, loss = 0.28391560\n",
      "Iteration 337, loss = 0.28079966\n",
      "Iteration 338, loss = 0.27873622\n",
      "Iteration 339, loss = 0.27823884\n",
      "Iteration 340, loss = 0.27815471\n",
      "Iteration 341, loss = 0.27876231\n",
      "Iteration 342, loss = 0.27920850\n",
      "Iteration 343, loss = 0.27556628\n",
      "Iteration 344, loss = 0.27448265\n",
      "Iteration 345, loss = 0.27705588\n",
      "Iteration 346, loss = 0.27800169\n",
      "Iteration 347, loss = 0.27455455\n",
      "Iteration 348, loss = 0.27538543\n",
      "Iteration 349, loss = 0.28182940\n",
      "Iteration 350, loss = 0.27501146\n",
      "Iteration 351, loss = 0.27456152\n",
      "Iteration 352, loss = 0.27581195\n",
      "Iteration 353, loss = 0.27291276\n",
      "Iteration 354, loss = 0.27485383\n",
      "Iteration 355, loss = 0.27319640\n",
      "Iteration 356, loss = 0.27217457\n",
      "Iteration 357, loss = 0.27161439\n",
      "Iteration 358, loss = 0.27181556\n",
      "Iteration 359, loss = 0.27382880\n",
      "Iteration 360, loss = 0.27012271\n",
      "Iteration 361, loss = 0.27399813\n",
      "Iteration 362, loss = 0.27129991\n",
      "Iteration 363, loss = 0.27107308\n",
      "Iteration 364, loss = 0.27106511\n",
      "Iteration 365, loss = 0.26946828\n",
      "Iteration 366, loss = 0.27111750\n",
      "Iteration 367, loss = 0.27605264\n",
      "Iteration 368, loss = 0.26995235\n",
      "Iteration 369, loss = 0.27112207\n",
      "Iteration 370, loss = 0.26463133\n",
      "Iteration 371, loss = 0.27174246\n",
      "Iteration 372, loss = 0.26936862\n",
      "Iteration 373, loss = 0.27069323\n",
      "Iteration 374, loss = 0.27294080\n",
      "Iteration 375, loss = 0.26924994\n",
      "Iteration 376, loss = 0.26829756\n",
      "Iteration 377, loss = 0.27230560\n",
      "Iteration 378, loss = 0.26591456\n",
      "Iteration 379, loss = 0.27249623\n",
      "Iteration 380, loss = 0.26754935\n",
      "Iteration 381, loss = 0.26441834\n",
      "Iteration 382, loss = 0.26290752\n",
      "Iteration 383, loss = 0.26188687\n",
      "Iteration 384, loss = 0.26315079\n",
      "Iteration 385, loss = 0.26505424\n",
      "Iteration 386, loss = 0.26656345\n",
      "Iteration 387, loss = 0.26308434\n",
      "Iteration 388, loss = 0.26312871\n",
      "Iteration 389, loss = 0.26345013\n",
      "Iteration 390, loss = 0.26326383\n",
      "Iteration 391, loss = 0.26971396\n",
      "Iteration 392, loss = 0.25993918\n",
      "Iteration 393, loss = 0.26550096\n",
      "Iteration 394, loss = 0.26113960\n",
      "Iteration 395, loss = 0.26209746\n",
      "Iteration 396, loss = 0.26335684\n",
      "Iteration 397, loss = 0.26012352\n",
      "Iteration 398, loss = 0.26250741\n",
      "Iteration 399, loss = 0.26040571\n",
      "Iteration 400, loss = 0.26383285\n",
      "Iteration 401, loss = 0.25965638\n",
      "Iteration 402, loss = 0.26312586\n",
      "Iteration 403, loss = 0.25778363\n",
      "Iteration 404, loss = 0.25568356\n",
      "Iteration 405, loss = 0.25979192\n",
      "Iteration 406, loss = 0.25731202\n",
      "Iteration 407, loss = 0.25480428\n",
      "Iteration 408, loss = 0.26154865\n",
      "Iteration 409, loss = 0.26399020\n",
      "Iteration 410, loss = 0.26055517\n",
      "Iteration 411, loss = 0.25311493\n",
      "Iteration 412, loss = 0.25162247\n",
      "Iteration 413, loss = 0.25747582\n",
      "Iteration 414, loss = 0.25831162\n",
      "Iteration 415, loss = 0.25168509\n",
      "Iteration 416, loss = 0.25580761\n",
      "Iteration 417, loss = 0.25086512\n",
      "Iteration 418, loss = 0.25220065\n",
      "Iteration 419, loss = 0.25478270\n",
      "Iteration 420, loss = 0.25505573\n",
      "Iteration 421, loss = 0.25472690\n",
      "Iteration 422, loss = 0.25348854\n",
      "Iteration 423, loss = 0.25384880\n",
      "Iteration 424, loss = 0.24934099\n",
      "Iteration 425, loss = 0.25656092\n",
      "Iteration 426, loss = 0.25248187\n",
      "Iteration 427, loss = 0.25234853\n",
      "Iteration 428, loss = 0.25276994\n",
      "Iteration 429, loss = 0.25191536\n",
      "Iteration 430, loss = 0.25399110\n",
      "Iteration 431, loss = 0.25497375\n",
      "Iteration 432, loss = 0.25121878\n",
      "Iteration 433, loss = 0.25138342\n",
      "Iteration 434, loss = 0.24451985\n",
      "Iteration 435, loss = 0.24962584\n",
      "Iteration 436, loss = 0.24990516\n",
      "Iteration 437, loss = 0.24344157\n",
      "Iteration 438, loss = 0.24591288\n",
      "Iteration 439, loss = 0.25144630\n",
      "Iteration 440, loss = 0.24926050\n",
      "Iteration 441, loss = 0.24433671\n",
      "Iteration 442, loss = 0.24716320\n",
      "Iteration 443, loss = 0.24469543\n",
      "Iteration 444, loss = 0.24846908\n",
      "Iteration 445, loss = 0.24728913\n",
      "Iteration 446, loss = 0.24878894\n",
      "Iteration 447, loss = 0.24434462\n",
      "Iteration 448, loss = 0.24640019\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "# Try with MLPClassifier\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=1)\n",
    "\n",
    "clf = MLPClassifier(random_state=1, max_iter=1000, verbose = True, hidden_layer_sizes=(128,128,128)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "f8725be2-5037-4d25-9251-60a0b84f2857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "6edc9ba6-79dc-480d-a6bb-43ba55b965ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86      4674\n",
      "           1       0.19      0.15      0.17       935\n",
      "\n",
      "    accuracy                           0.76      5609\n",
      "   macro avg       0.52      0.51      0.51      5609\n",
      "weighted avg       0.73      0.76      0.74      5609\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "cea867af-ef78-48f8-bbe0-90e46efe2d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the train set\n",
    "y_pred = clf.predict(X_train)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "88212e87-77e9-4bd4-9d2a-3c841ecf3a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94     14021\n",
      "           1       0.76      0.58      0.66      2804\n",
      "\n",
      "    accuracy                           0.90     16825\n",
      "   macro avg       0.84      0.77      0.80     16825\n",
      "weighted avg       0.89      0.90      0.89     16825\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db7b1e0-a8b8-4061-acb1-a8e1bb4d2dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78afac6-1d75-4914-9446-4654b86a702b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GDAL 3.9.0)",
   "language": "python",
   "name": "gdal390"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
